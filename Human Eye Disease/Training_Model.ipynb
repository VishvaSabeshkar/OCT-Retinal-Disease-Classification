{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdde53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d6791",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f481308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76515 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set =image_dataset_from_directory(\n",
    "    \"train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89d811b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21861 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set =image_dataset_from_directory(\n",
    "    \"val\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8407d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a30f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c70577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float.h5\n",
      "22661472/22661472 [==============================] - 15s 1us/step\n"
     ]
    }
   ],
   "source": [
    "mobNetV =tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    classes=1000,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "837ccc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0561732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.Input(shape=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "555dfb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(mobNetV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c998e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "110f8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\n",
    "    \"accuracy\", \n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d75bff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=metrics_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1384cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3large (Functiona  (None, 1000)             5507432   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,511,436\n",
      "Trainable params: 5,487,036\n",
      "Non-trainable params: 24,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c19b78db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4783/4783 [==============================] - 482s 101ms/step - loss: 1.0194 - accuracy: 0.8372 - precision: 0.9550 - recall: 0.1211 - val_loss: 0.7870 - val_accuracy: 0.8995 - val_precision: 0.9442 - val_recall: 0.4683\n",
      "Epoch 2/15\n",
      "4783/4783 [==============================] - 489s 102ms/step - loss: 0.6482 - accuracy: 0.8936 - precision: 0.9198 - recall: 0.7896 - val_loss: 0.5185 - val_accuracy: 0.8876 - val_precision: 0.9650 - val_recall: 0.7896\n",
      "Epoch 3/15\n",
      "4783/4783 [==============================] - 493s 103ms/step - loss: 0.4335 - accuracy: 0.9177 - precision: 0.9640 - recall: 0.8528 - val_loss: 0.3801 - val_accuracy: 0.9267 - val_precision: 0.9756 - val_recall: 0.8423\n",
      "Epoch 4/15\n",
      "4783/4783 [==============================] - 492s 103ms/step - loss: 0.3023 - accuracy: 0.9543 - precision: 0.9696 - recall: 0.8866 - val_loss: 0.2568 - val_accuracy: 0.9563 - val_precision: 0.9688 - val_recall: 0.9462\n",
      "Epoch 5/15\n",
      "4783/4783 [==============================] - 493s 103ms/step - loss: 0.2172 - accuracy: 0.9627 - precision: 0.9672 - recall: 0.9582 - val_loss: 0.1888 - val_accuracy: 0.9668 - val_precision: 0.9689 - val_recall: 0.9643\n",
      "Epoch 6/15\n",
      "4783/4783 [==============================] - 492s 103ms/step - loss: 0.1607 - accuracy: 0.9702 - precision: 0.9731 - recall: 0.9669 - val_loss: 0.1524 - val_accuracy: 0.9656 - val_precision: 0.9689 - val_recall: 0.9620\n",
      "Epoch 7/15\n",
      "4783/4783 [==============================] - 494s 103ms/step - loss: 0.1228 - accuracy: 0.9762 - precision: 0.9779 - recall: 0.9744 - val_loss: 0.1365 - val_accuracy: 0.9695 - val_precision: 0.9708 - val_recall: 0.9679\n",
      "Epoch 8/15\n",
      "4783/4783 [==============================] - 492s 103ms/step - loss: 0.0994 - accuracy: 0.9802 - precision: 0.9812 - recall: 0.9790 - val_loss: 0.1160 - val_accuracy: 0.9737 - val_precision: 0.9750 - val_recall: 0.9718\n",
      "Epoch 9/15\n",
      "4783/4783 [==============================] - 498s 104ms/step - loss: 0.0839 - accuracy: 0.9830 - precision: 0.9837 - recall: 0.9821 - val_loss: 0.1112 - val_accuracy: 0.9723 - val_precision: 0.9736 - val_recall: 0.9711\n",
      "Epoch 10/15\n",
      "4783/4783 [==============================] - 499s 104ms/step - loss: 0.0706 - accuracy: 0.9857 - precision: 0.9863 - recall: 0.9851 - val_loss: 0.2479 - val_accuracy: 0.9232 - val_precision: 0.9259 - val_recall: 0.9208\n",
      "Epoch 11/15\n",
      "4783/4783 [==============================] - 495s 104ms/step - loss: 0.0606 - accuracy: 0.9880 - precision: 0.9886 - recall: 0.9876 - val_loss: 0.1332 - val_accuracy: 0.9683 - val_precision: 0.9689 - val_recall: 0.9675\n",
      "Epoch 12/15\n",
      "4783/4783 [==============================] - 496s 104ms/step - loss: 0.0529 - accuracy: 0.9895 - precision: 0.9900 - recall: 0.9891 - val_loss: 0.1029 - val_accuracy: 0.9753 - val_precision: 0.9760 - val_recall: 0.9748\n",
      "Epoch 13/15\n",
      "4783/4783 [==============================] - 495s 103ms/step - loss: 0.0511 - accuracy: 0.9893 - precision: 0.9897 - recall: 0.9890 - val_loss: 0.1031 - val_accuracy: 0.9743 - val_precision: 0.9750 - val_recall: 0.9739\n",
      "Epoch 14/15\n",
      "4783/4783 [==============================] - 497s 104ms/step - loss: 0.0445 - accuracy: 0.9910 - precision: 0.9913 - recall: 0.9908 - val_loss: 0.4158 - val_accuracy: 0.8857 - val_precision: 0.8875 - val_recall: 0.8829\n",
      "Epoch 15/15\n",
      "4783/4783 [==============================] - 495s 104ms/step - loss: 0.0425 - accuracy: 0.9910 - precision: 0.9913 - recall: 0.9907 - val_loss: 0.1103 - val_accuracy: 0.9720 - val_precision: 0.9728 - val_recall: 0.9712\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    x = training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c7aa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Trained_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e1a816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.019428014755249,\n",
       "  0.6482160091400146,\n",
       "  0.43353232741355896,\n",
       "  0.3022870719432831,\n",
       "  0.2172396183013916,\n",
       "  0.16067421436309814,\n",
       "  0.12280230969190598,\n",
       "  0.09944693744182587,\n",
       "  0.08387169241905212,\n",
       "  0.0706123486161232,\n",
       "  0.06055669113993645,\n",
       "  0.052932292222976685,\n",
       "  0.05108383670449257,\n",
       "  0.04454481601715088,\n",
       "  0.042467378079891205],\n",
       " 'accuracy': [0.8371822237968445,\n",
       "  0.8936156034469604,\n",
       "  0.9177154898643494,\n",
       "  0.9542834758758545,\n",
       "  0.9627131819725037,\n",
       "  0.970241129398346,\n",
       "  0.9761745929718018,\n",
       "  0.9802130460739136,\n",
       "  0.9830490946769714,\n",
       "  0.9856759905815125,\n",
       "  0.9880415797233582,\n",
       "  0.9894922375679016,\n",
       "  0.9893093109130859,\n",
       "  0.9910344481468201,\n",
       "  0.9909560084342957],\n",
       " 'precision': [0.9549763202667236,\n",
       "  0.9198282957077026,\n",
       "  0.9639702439308167,\n",
       "  0.9695865511894226,\n",
       "  0.9672167897224426,\n",
       "  0.9730895757675171,\n",
       "  0.9779115915298462,\n",
       "  0.9812291860580444,\n",
       "  0.9837278127670288,\n",
       "  0.9863379597663879,\n",
       "  0.9885788559913635,\n",
       "  0.989967405796051,\n",
       "  0.9897329211235046,\n",
       "  0.9913042187690735,\n",
       "  0.9913296103477478],\n",
       " 'recall': [0.12113964557647705,\n",
       "  0.789622962474823,\n",
       "  0.8528392910957336,\n",
       "  0.8866366147994995,\n",
       "  0.9581912159919739,\n",
       "  0.9669215083122253,\n",
       "  0.9743841290473938,\n",
       "  0.9790106415748596,\n",
       "  0.9820950031280518,\n",
       "  0.985061764717102,\n",
       "  0.9875710606575012,\n",
       "  0.9891393780708313,\n",
       "  0.9889956116676331,\n",
       "  0.9907730221748352,\n",
       "  0.9907076954841614],\n",
       " 'val_loss': [0.7870160341262817,\n",
       "  0.5184502005577087,\n",
       "  0.38008588552474976,\n",
       "  0.2567736506462097,\n",
       "  0.18881818652153015,\n",
       "  0.15239295363426208,\n",
       "  0.1365271359682083,\n",
       "  0.11600615084171295,\n",
       "  0.11119066178798676,\n",
       "  0.24791692197322845,\n",
       "  0.13316626846790314,\n",
       "  0.10294269025325775,\n",
       "  0.1031438484787941,\n",
       "  0.4157795310020447,\n",
       "  0.11027991771697998],\n",
       " 'val_accuracy': [0.899501383304596,\n",
       "  0.8875623345375061,\n",
       "  0.9266730546951294,\n",
       "  0.9563149213790894,\n",
       "  0.9668359160423279,\n",
       "  0.9655550718307495,\n",
       "  0.9694890379905701,\n",
       "  0.973743200302124,\n",
       "  0.97227942943573,\n",
       "  0.9231508374214172,\n",
       "  0.9682996869087219,\n",
       "  0.9753442406654358,\n",
       "  0.9743378758430481,\n",
       "  0.8856868147850037,\n",
       "  0.9720049500465393],\n",
       " 'val_precision': [0.9442036151885986,\n",
       "  0.9649505019187927,\n",
       "  0.9756278395652771,\n",
       "  0.968761682510376,\n",
       "  0.9689280986785889,\n",
       "  0.9689458012580872,\n",
       "  0.9708189964294434,\n",
       "  0.9749885201454163,\n",
       "  0.9736286997795105,\n",
       "  0.9258543848991394,\n",
       "  0.9688960313796997,\n",
       "  0.9760465621948242,\n",
       "  0.9750412106513977,\n",
       "  0.8874890804290771,\n",
       "  0.9727847576141357],\n",
       " 'val_recall': [0.4683225750923157,\n",
       "  0.789625346660614,\n",
       "  0.8423219323158264,\n",
       "  0.9462055563926697,\n",
       "  0.9642742872238159,\n",
       "  0.9619870781898499,\n",
       "  0.9678879976272583,\n",
       "  0.9718219637870789,\n",
       "  0.9710900783538818,\n",
       "  0.920772135257721,\n",
       "  0.9675220847129822,\n",
       "  0.9748410582542419,\n",
       "  0.9739261865615845,\n",
       "  0.8829421997070312,\n",
       "  0.9712272882461548]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7759697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Training_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_history.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
